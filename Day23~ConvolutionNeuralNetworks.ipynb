{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution Neural Networks\n",
    "#Step1-Convolution Operation\n",
    "#Step1(b)-ReLU layer\n",
    "#Step2-Pooling(also called down sampling)\n",
    "#Step3-Flattening\n",
    "#Step4-Full Connection\n",
    "#Softmax and Cross-Entropy(Loss fxn for classification in CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1-Convolution\n",
    "#Input Image*Feature Detector(3*3) = Feature Map\n",
    "#Step1(b)-ReLU~Only non negative (To remove linearity)\n",
    "#Step2-Max Pooling~Recording the maximum value in the box(2*2) (Spatial Invariance)\n",
    "#Sub Sampling~Average Pooling\n",
    "#Step3-Flattening~converting the pooled matrix into vector\n",
    "#Step4-Full Conection-Adding ANN to CNN\n",
    "#In ANN, hidden layers doesn't need to be fully connected layers but in CNN, hidden layers have to be fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Part-1 ~ Building the CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Adding the different CNN layers\n",
    "#Step1-Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape =(64, 64, 3), activation = 'relu'))\n",
    "#32 -no. of filters, 3-no. of rows in each filter, 3-no. of columns in each filter \n",
    "#3-no. of channels(3 for RGB and 1 for b&w), 64*64 dimensions of i/p image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step2-Max Pooling(Size of resulting matrix after applying max pooling is (Size of feature map)/2\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step3-Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Step4-Full Connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8008 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=8000, epochs=25, validation_data=<keras_pre..., validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1519s 190ms/step - loss: 0.4011 - acc: 0.8112 - val_loss: 0.6959 - val_acc: 0.7584\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 1643s 205ms/step - loss: 0.1530 - acc: 0.9407 - val_loss: 1.0630 - val_acc: 0.7629\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 1828s 229ms/step - loss: 0.0828 - acc: 0.9693 - val_loss: 1.2730 - val_acc: 0.7693\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 3007s 376ms/step - loss: 0.0581 - acc: 0.9795 - val_loss: 1.6951 - val_acc: 0.7477\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1549s 194ms/step - loss: 0.0449 - acc: 0.9846 - val_loss: 1.7539 - val_acc: 0.7408\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1538s 192ms/step - loss: 0.0373 - acc: 0.9873 - val_loss: 1.6735 - val_acc: 0.7682\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1585s 198ms/step - loss: 0.0323 - acc: 0.9892 - val_loss: 1.7148 - val_acc: 0.7639\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1911s 239ms/step - loss: 0.0287 - acc: 0.9905 - val_loss: 1.8894 - val_acc: 0.7492\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 55132s 7s/step - loss: 0.0241 - acc: 0.9921 - val_loss: 1.9743 - val_acc: 0.7647\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1442s 180ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 1.9268 - val_acc: 0.7649\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1613s 202ms/step - loss: 0.0208 - acc: 0.9934 - val_loss: 1.9877 - val_acc: 0.7545\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1463s 183ms/step - loss: 0.0193 - acc: 0.9939 - val_loss: 2.0714 - val_acc: 0.7510\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 6012s 752ms/step - loss: 0.0175 - acc: 0.9945 - val_loss: 1.9579 - val_acc: 0.7674\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2169s 271ms/step - loss: 0.0165 - acc: 0.9948 - val_loss: 2.1564 - val_acc: 0.7559\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 2059s 257ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 2.0641 - val_acc: 0.7510\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1551s 194ms/step - loss: 0.0143 - acc: 0.9956 - val_loss: 2.1775 - val_acc: 0.7515\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 2837s 355ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 2.1917 - val_acc: 0.7577\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1657s 207ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 2.2665 - val_acc: 0.7529\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1569s 196ms/step - loss: 0.0115 - acc: 0.9966 - val_loss: 2.1898 - val_acc: 0.7503\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 12570s 2s/step - loss: 0.0120 - acc: 0.9964 - val_loss: 2.2107 - val_acc: 0.7564\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1496s 187ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 2.0967 - val_acc: 0.7657\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1698s 212ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 2.2174 - val_acc: 0.7686\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1581s 198ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 2.1477 - val_acc: 0.7559\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2888s 361ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 2.2886 - val_acc: 0.7602\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 3576s 447ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 2.3450 - val_acc: 0.7564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8685e290b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the CNN to images\n",
    "#Before fitting the CNN, we'll use image augmentation to prevent overfitting\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(   'dataset/training_set',\n",
    "                                                    target_size=(64, 64),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "        \n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "                                                    'dataset/test_set',\n",
    "                                                    target_size=(64, 64),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                    steps_per_epoch=8000,\n",
    "                    epochs=25,\n",
    "                    validation_data=test_set,\n",
    "                    nb_val_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can increase the accuracy of test set by two ways ~\n",
    "#-By increasing the number of convolution layers or by increasing the number of fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  if sys.path[0] == '':\n",
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#Adding Second Convolutional Layer in our mdel to increase accuracy\n",
    "#Initialising the CNN\n",
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape =(64, 64, 3), activation = 'relu'))\n",
    "#Step2-Max Pooling(Size of resulting matrix after applying max pooling is (Size of feature map)/2\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#Step3-Flattening\n",
    "classifier.add(Flatten())\n",
    "#Step4-Full Connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "#Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8008 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/anubansal17/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=8000, epochs=25, validation_data=<keras_pre..., validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 78758s 10s/step - loss: 0.3486 - acc: 0.8349 - val_loss: 0.6415 - val_acc: 0.7916\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2878s 360ms/step - loss: 0.0921 - acc: 0.9658 - val_loss: 0.9503 - val_acc: 0.7970\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 10568s 1s/step - loss: 0.0480 - acc: 0.9831 - val_loss: 1.1621 - val_acc: 0.8037\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 1746s 218ms/step - loss: 0.0351 - acc: 0.9878 - val_loss: 1.3403 - val_acc: 0.7876\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1475s 184ms/step - loss: 0.0274 - acc: 0.9908 - val_loss: 1.3566 - val_acc: 0.8018\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2655s 332ms/step - loss: 0.0231 - acc: 0.9922 - val_loss: 1.3788 - val_acc: 0.7979\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 11450s 1s/step - loss: 0.0204 - acc: 0.9935 - val_loss: 1.4731 - val_acc: 0.7969\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1642s 205ms/step - loss: 0.0182 - acc: 0.9941 - val_loss: 1.5102 - val_acc: 0.7955\n",
      "Epoch 9/25\n",
      "7999/8000 [============================>.] - ETA: 6s - loss: 0.0160 - acc: 0.9948 "
     ]
    }
   ],
   "source": [
    "#fitting the CNN to images\n",
    "#Before fitting the CNN, we'll use image augmentation to prevent overfitting\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(   'dataset/training_set',\n",
    "                                                    target_size=(64, 64),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "        \n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "                                                    'dataset/test_set',\n",
    "                                                    target_size=(64, 64),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                    steps_per_epoch=8000,\n",
    "                    epochs=25,\n",
    "                    validation_data=test_set,\n",
    "                    nb_val_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
